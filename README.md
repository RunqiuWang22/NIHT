# NIHT
Normalized Iterative Hard Thresholding Algorithm for model selection

Traditional variable selection methods such as stepwise and best subset are essentially L0 penalized regression. However, solving L0 optimization solution is a NP-hard problem and computationally unfeasible when the number of variables is large. Popular variable selection methods such as Lasso, SCAD, MCP use relax penalties to approximate L0 solution and result in too many false positives in GWAS because of the sparsity. In my work, the Normalized Iterative Hard Thresholding (IHT) algorithm is implemented in logistic regression to obtain better L0 optimization solution for variable selection. Simulation shows that this algorithm selects nearly true model even when the dimensionality is extremely high. Compared with other dominant variable selection methods, this algorithm demonstrates better performance on both prediction accuracy and true positives.
